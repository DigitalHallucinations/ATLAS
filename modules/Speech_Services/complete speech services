#Speech_Services integration

# --------------------------------------------------------------------

# modules/Speech_Services/base.py

from abc import ABC, abstractmethod

class BaseTTS(ABC):
    @abstractmethod
    async def text_to_speech(self, text: str):
        pass

    @abstractmethod
    def set_voice(self, voice: dict):
        pass

    @abstractmethod
    def get_voices(self) -> list:
        pass

    @abstractmethod
    def set_tts(self, value: bool):
        pass

    @abstractmethod
    def get_tts(self) -> bool:
        pass

class BaseSTT(ABC):
    @abstractmethod
    def listen(self):
        pass

    @abstractmethod
    def stop_listening(self):
        pass

    @abstractmethod
    def transcribe(self, audio_file: str) -> str:
        pass

# modules/Speech_Services/Eleven_Labs/elevenlabs_tts.py

"""
Module: elevenlabs_tts.py
Description:
    Enterprise production–ready implementation of Eleven Labs Text-to-Speech integration.
    This provider now checks for an API key configuration. If the API key is not provided,
    the service logs a warning and disables TTS functionality without breaking the application.
    
Usage:
    The API key can be set via the environment (or via the ConfigManager in the Speech Settings UI).
    If not provided, the provider remains disabled.
    
Author: Jeremy Shows - Digital Hallucinations
Date: 05-11-2025
"""

import os
import re
import pygame
import threading
import requests
from datetime import datetime
from dotenv import load_dotenv
from modules.logging.logger import setup_logger
from .base import BaseTTS

logger = setup_logger('eleven_labs_tts.py')

CHUNK_SIZE = 1024 

class ElevenLabsTTS(BaseTTS):
    def __init__(self):
        self._use_tts = False
        self.voice_ids = []
        self.configured = False  # Flag indicating whether API key is configured.
        self.load_voices()

    def load_voices(self):
        """
        Loads available voices from the Eleven Labs API.
        Reads the XI_API_KEY from the environment.
        If the API key is not provided, logs a warning and disables further functionality.
        """
        load_dotenv()
        XI_API_KEY = os.getenv("XI_API_KEY")
        if not XI_API_KEY:
            logger.error("XI_API_KEY not found. Eleven Labs TTS is disabled. Please configure the API key.")
            self.configured = False
            self.voice_ids = []
            return  # Do not raise an exception; allow the app to continue.
        else:
            self.configured = True

        url = "https://api.elevenlabs.io/v1/voices"
        headers = {
            "Accept": "application/json",
            "xi-api-key": XI_API_KEY,
            "Content-Type": "application/json"
        }

        logger.info("Fetching voices from Eleven Labs API...")
        response = requests.get(url, headers=headers)
        if response.ok:
            data = response.json()
            self.voice_ids = [{'voice_id': voice['voice_id'], 'name': voice['name']} for voice in data.get('voices', [])]
            if self.voice_ids:
                logger.info(f"Loaded {len(self.voice_ids)} voices from Eleven Labs.")
            else:
                logger.error("No voices found in Eleven Labs.")
        else:
            logger.error(f"Failed to fetch voices: {response.text}")
            self.voice_ids = []

    def play_audio(self, filename):
        """
        Plays the specified audio file.
        """
        logger.info(f"Playing audio file: {filename}")
        pygame.mixer.init()
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        logger.info("Audio playback finished.")

    def contains_code(self, text: str) -> bool:
        """
        Checks if the provided text contains any code blocks.
        
        Args:
            text (str): Text to check.
        
        Returns:
            bool: True if code is detected, False otherwise.
        """
        logger.debug(f"Checking if text contains code: {text}")
        return "<code>" in text

    async def text_to_speech(self, text: str):
        """
        Converts text to speech by sending a request to the Eleven Labs API.
        If TTS is disabled or the service is not configured, the method logs the state and returns.
        
        Args:
            text (str): Text to be converted to speech.
        """
        if not self._use_tts:
            logger.info("TTS is turned off.")
            return

        if not self.configured:
            logger.error("Eleven Labs TTS is not configured (missing API key).")
            return

        if self.contains_code(text):
            logger.info("Skipping TTS as the text contains code.")
            text = re.sub(r"`[^`]*`", "", text)

        if not self.voice_ids:
            logger.error("No voice IDs available for Eleven Labs TTS.")
            return

        voice_id = self.voice_ids[0]['voice_id']
        tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"
       
        headers = {
            "Accept": "application/json",
            "xi-api-key": os.getenv("XI_API_KEY")
        }

        data = {
            "text": text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.8,
                "style": 0.0,
                "use_speaker_boost": True
            }
        }

        logger.info(f"Sending TTS request to Eleven Labs with text: {text}")
        response = requests.post(tts_url, headers=headers, json=data, stream=True)

        logger.info(f"Eleven Labs API response status: {response.status_code}")
        if response.ok:
            logger.info("Received TTS response successfully.")
            output_dir = "assets/SCOUT/tts_mp3/"
            os.makedirs(output_dir, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            output_path = os.path.join(output_dir, f"output_{timestamp}.mp3")
            
            with open(output_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=CHUNK_SIZE):
                    f.write(chunk)
            logger.info(f"Audio saved to {output_path}")
            threading.Thread(target=self.play_audio, args=(output_path,)).start()
        else:
            logger.error(f"Eleven Labs TTS Error: {response.text}")

    def set_voice(self, voice: dict):
        """
        Sets the active voice to the one matching the provided voice dictionary.
        
        Args:
            voice (dict): Dictionary containing voice details.
        """
        for i, v in enumerate(self.voice_ids):
            if v['name'] == voice['name'] and v['voice_id'] == voice['voice_id']:
                self.voice_ids.pop(i)
                self.voice_ids.insert(0, voice)
                logger.info(f"Voice set to: {voice['name']} with ID: {voice['voice_id']}")
                return
        logger.error(f"Voice {voice['name']} not found in Eleven Labs voices.")

    def get_voices(self) -> list:
        """
        Returns a list of available voices.
        
        Returns:
            list: Available voices.
        """
        return self.voice_ids

    def set_tts(self, value: bool):
        """
        Enables or disables TTS functionality.
        
        Args:
            value (bool): True to enable, False to disable.
        """
        self._use_tts = value
        logger.info(f"Eleven Labs TTS set to: {self._use_tts}")

    def get_tts(self) -> bool:
        """
        Gets the current TTS enabled status.
        
        Returns:
            bool: True if enabled, False otherwise.
        """
        return self._use_tts


# modules/Speech_Services/whisper_stt.py

"""
Module: whisper_stt.py
Description:
    Implements a speech-to-text provider using OpenAI Whisper.
    Supports both local transcription (via the whisper Python package)
    and online transcription (via OpenAI's API). If the API key for online mode
    is not configured, online transcription is disabled.
    
Author: Jeremy Shows - Digital Hallucinations
Date: 05-11-2025
"""

import os
import numpy as np
import sounddevice as sd
import soundfile as sf
import logging

logger = logging.getLogger(__name__)

class WhisperSTT:
    """
    Speech-to-Text provider using OpenAI Whisper.
    Supports both local and online modes.
    
    Args:
        mode (str): Either "local" or "online". If "online", an API key must be set.
        model_name (str): The Whisper model to load in local mode.
        fs (int): The sampling frequency.
    """
    def __init__(self, mode="local", model_name="base", fs=16000):
        self.mode = mode.lower()  # "local" or "online"
        self.fs = fs
        self.frames = []
        self.recording = False
        self.audio_file = None

        # Initialize microphone stream.
        self.stream = sd.InputStream(callback=self.callback, channels=1, samplerate=self.fs)

        if self.mode == "local":
            try:
                import whisper
                self.model = whisper.load_model(model_name)
                logger.info(f"Loaded local Whisper model: {model_name}")
            except Exception as e:
                logger.error(f"Failed to load local Whisper model: {e}")
                raise e
        else:
            try:
                import openai
                self.api_key = os.getenv("OPENAI_API_KEY")
                if not self.api_key:
                    logger.error("OPENAI_API_KEY not set. Whisper online mode is disabled.")
                    self.online_configured = False
                    # Online mode disabled; you can decide to either fall back or raise an exception.
                else:
                    openai.api_key = self.api_key
                    self.online_configured = True
                    logger.info("Configured OpenAI API for Whisper online mode.")
            except Exception as e:
                logger.error(f"Failed to initialize Whisper online mode: {e}")
                raise e

    def callback(self, indata, frames, time, status):
        """
        Callback for the audio input stream to store audio frames.
        """
        if self.recording:
            self.frames.append(indata.copy())

    def listen(self):
        """
        Starts recording audio from the microphone.
        """
        self.frames = []
        self.recording = True
        self.stream.start()
        logger.info("Whisper STT listening...")

    def stop_listening(self):
        """
        Stops recording and saves the audio file.
        """
        if self.recording:
            self.stream.stop()
            self.recording = False
            self.save_recording()
            logger.info("Whisper STT stopped listening.")
        self.stream.close()
        self.frames = []

    def save_recording(self, filename="whisper_output.wav"):
        """
        Saves the recorded audio to a file.
        
        Args:
            filename (str): The name of the file to save.
        """
        output_dir = os.path.join("assets", "user", "sst_whisper")
        os.makedirs(output_dir, exist_ok=True)
        output_file = os.path.join(output_dir, filename)
        if self.frames:
            data = np.concatenate(self.frames)
            sf.write(output_file, data, self.fs)
            logger.info(f"Saved Whisper audio to {output_file}")
            self.audio_file = output_file
        else:
            logger.warning("No audio frames to save.")

    def transcribe(self, audio_file=None) -> str:
        """
        Transcribes the audio file using the selected Whisper mode.
        In online mode, if the API key is not configured, returns an error message.
        
        Args:
            audio_file (str): Path to the audio file; if not provided, uses the last recorded file.
            
        Returns:
            str: The transcribed text.
        """
        if not audio_file:
            if not self.audio_file:
                logger.error("No audio file available for transcription.")
                return ""
            audio_file = self.audio_file

        if self.mode == "local":
            try:
                result = self.model.transcribe(audio_file)
                logger.info("Local Whisper transcription complete.")
                return result.get("text", "")
            except Exception as e:
                logger.error(f"Error during local transcription: {e}")
                return ""
        else:
            if not getattr(self, "online_configured", False):
                logger.error("Online mode is not configured due to missing API key.")
                return "Online transcription unavailable (API key missing)"
            try:
                import openai
                with open(audio_file, "rb") as f:
                    result = openai.Audio.transcribe("whisper-1", f)
                logger.info("Online Whisper transcription complete.")
                return result.get("text", "")
            except Exception as e:
                logger.error(f"Error during online transcription: {e}")
                return ""


# modules\Speech_Services\Ggl_stt.py

import os
import sounddevice as sd
import numpy as np
import soundfile as sf
from google.cloud import speech_v1p1beta1 as speech
from modules.logging.logger import setup_logger

logger = setup_logger('Ggl_stt.py')

class GoogleSTT:
    def __init__(self, fs=16000, sample_rate_hertz=16000, enable_automatic_punctuation=True):
        logger.info("Initializing GoogleSTT")
        self.client = speech.SpeechClient()
        self.config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",
            enable_automatic_punctuation=enable_automatic_punctuation
        )
        
        self.fs = fs
        self.frames = []
        self.recording = False
        self.stream = sd.InputStream(callback=self.callback, channels=1, samplerate=self.fs)

    def callback(self, indata, frames, time, status):
        if self.recording:
            self.frames.append(indata.copy())

    def listen(self):  
        logger.info("Listening...")
        self.frames = []
        self.recording = True
        self.stream = sd.InputStream(callback=self.callback, channels=1, samplerate=self.fs)
        self.stream.start()

    def stop_listening(self):
        logger.info("Stopping listening")
        if self.recording:
            self.stream.stop()
            self.recording = False
            self.save_recording()
            logger.debug("Recording stopped")
        else:
            logger.warning("Tried to stop listening, but was not recording")
        self.stream.close()
        self.frames = []

    def save_recording(self, filename='output.wav'):
        logger.info("Saving recording")
        output_dir = 'assets/user/sst_output'
        os.makedirs(output_dir, exist_ok=True)  
        output_file = os.path.join(output_dir, filename)

        if self.frames:
            data = np.concatenate(self.frames)
            sf.write(output_file, data, self.fs)
            logger.info(f"Audio recorded and saved as {output_file}")
        else:
            logger.warning("No frames to save")

    def transcribe(self, audio_file):
        logger.info(f"Transcribing file {audio_file}")
        audio_file_path = os.path.join('assets/user/sst_output', audio_file)

        with open(audio_file_path, 'rb') as audio:
            audio_content = audio.read()

        audio = speech.RecognitionAudio(content=audio_content)
        response = self.client.recognize(config=self.config, audio=audio)

        if not os.path.exists(audio_file_path):
            logger.error(f"Audio file not found: {audio_file_path}")
            return "No audio file to transcribe"

        transcript = []
        for result in response.results:
            transcript.append(result.alternatives[0].transcript)

        # Delete the audio file after transcription
        os.remove(audio_file_path)
        logger.info(f"Deleted audio file {audio_file_path}")

        return ' '.join(transcript)
    
# modules/Speech_Services/Google/tts.py
# Description: Text to speech module using Google Cloud Text-to-Speech

import os
import re
import pygame
import threading
from google.cloud import speech_v1p1beta1 as speech
from modules.logging.logger import setup_logger
from .base import BaseTTS

logger = setup_logger('google_tts.py')

CHUNK_SIZE = 1024
OUTPUT_PATH = "assets/SCOUT/tts_mp3/output.mp3"

class GoogleTTS(BaseTTS):
    def __init__(self):
        self._use_tts = False
        self.voice = speech.VoiceSelectionParams(
            language_code="en-US",
            name="en-US-Wavenet-A"
        )
        self.client = speech.SpeechClient()

    def play_audio(self, filename):
        logger.info(f"Playing audio file: {filename}")
        pygame.mixer.init()
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        logger.info("Audio playback finished.")

    def contains_code(self, text: str) -> bool:
        logger.debug(f"Checking if text contains code: {text}")
        return "<code>" in text

    async def text_to_speech(self, text: str):
        if not self._use_tts:
            logger.info("TTS is turned off.")
            return

        if self.contains_code(text):
            logger.info("Skipping TTS as the text contains code.")
            text = re.sub(r"`[^`]*`", "", text)

        synthesis_input = speech.SynthesisInput(text=text)
        audio_config = speech.AudioConfig(
            audio_encoding=speech.AudioEncoding.MP3
        )

        try:
            response = self.client.synthesize_speech(
                input=synthesis_input,
                voice=self.voice,
                audio_config=audio_config
            )
            logger.info("Google TTS response received successfully.")
        except Exception as e:
            logger.error(f"Google TTS synthesis error: {e}")
            return

        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
        with open(OUTPUT_PATH, "wb") as out:
            out.write(response.audio_content)
            logger.info(f'Audio content written to "{OUTPUT_PATH}"')

        threading.Thread(target=self.play_audio, args=(OUTPUT_PATH,)).start()

    def set_voice(self, voice_name: str):
        self.voice = speech.VoiceSelectionParams(
            language_code=voice_name.split('-')[0] + '-' + voice_name.split('-')[1],
            name=voice_name,
        )
        logger.info(f"Google TTS voice set to: {voice_name}")

    def get_voices(self) -> list:
        voices = []
        try:
            response = self.client.list_voices()
            for voice in response.voices:
                for language_code in voice.language_codes:
                    voices.append({
                        'name': voice.name,
                        'language': language_code,
                        'ssml_gender': speech.SsmlVoiceGender(voice.ssml_gender).name,
                        'natural_sample_rate_hertz': voice.natural_sample_rate_hertz,
                    })
            logger.info(f"Google TTS: Found {len(voices)} voices.")
        except Exception as e:
            logger.error(f"Error fetching Google TTS voices: {e}")
        return voices

    def set_tts(self, value: bool):
        self._use_tts = value
        logger.info(f"Google TTS set to: {self._use_tts}")

    def get_tts(self) -> bool:
        return self._use_tts

# modules/speech_services/speech_manager.py

"""
Speech Manager Module
-----------------------
This module provides a unified interface for managing Text-to-Speech (TTS)
and Speech-to-Text (STT) services. It supports multiple providers (e.g.,
Eleven Labs, Google, and Whisper) and allows dynamic selection, addition, and
removal of providers. The manager also handles asynchronous initialization and
clean-up of services.

Author:Jeremy Shows - Digital Hallucinations
Date: 05-11-2025
"""

from typing import Dict, Any
from .elevenlabs_tts import ElevenLabsTTS
from .Google_tts import GoogleTTS
from .Google_stt import GoogleSTT
from modules.logging.logger import setup_logger
from ATLAS.config import ConfigManager

logger = setup_logger('speech_manager.py')

class SpeechManager:
    def __init__(self, config_manager: ConfigManager):
        """
        Initializes the SpeechManager.

        Args:
            config_manager (ConfigManager): Configuration manager for retrieving global settings.
        """
        self.config_manager = config_manager
        self.tts_services: Dict[str, Any] = {}
        self.stt_services: Dict[str, Any] = {}
        self.active_tts = None
        self.active_stt = None
        self._tts_enabled = False 

        self.initialize_services()

    async def initialize(self):
        """
        Perform any asynchronous initialization if required.
        Currently a placeholder for future asynchronous initialization.
        """
        pass

    def initialize_services(self):
        """
        Initializes available TTS and STT services.
        This method registers all providers and sets default active services.
        """
        logger.info("Initializing Speech Services...")

        # Initialize TTS services
        try:
            eleven_tts = ElevenLabsTTS()
            self.tts_services['eleven_labs'] = eleven_tts
            logger.info("Eleven Labs TTS initialized.")
        except Exception as e:
            logger.error(f"Failed to initialize Eleven Labs TTS: {e}")

        try:
            google_tts = GoogleTTS()
            self.tts_services['google'] = google_tts
            logger.info("Google TTS initialized.")
        except Exception as e:
            logger.error(f"Failed to initialize Google TTS: {e}")

        # Initialize STT services
        try:
            google_stt = GoogleSTT()
            self.stt_services['google'] = google_stt
            logger.info("Google STT initialized.")
        except Exception as e:
            logger.error(f"Failed to initialize Google STT: {e}")

        # Initialize Whisper STT services (local and online)
        try:
            from modules.Speech_Services.whisper_stt import WhisperSTT
            whisper_local = WhisperSTT(mode="local")
            self.stt_services['whisper_local'] = whisper_local
            logger.info("Whisper local STT initialized.")
        except Exception as e:
            logger.error(f"Failed to initialize Whisper local STT: {e}")

        try:
            from modules.Speech_Services.whisper_stt import WhisperSTT
            whisper_online = WhisperSTT(mode="online")
            self.stt_services['whisper_online'] = whisper_online
            logger.info("Whisper online STT initialized.")
        except Exception as e:
            logger.error(f"Failed to initialize Whisper online STT: {e}")

        # Set default active services
        if 'eleven_labs' in self.tts_services:
            self.active_tts = self.tts_services['eleven_labs']
            logger.info("Default TTS set to Eleven Labs.")
        elif 'google' in self.tts_services:
            self.active_tts = self.tts_services['google']
            logger.info("Default TTS set to Google.")

        # Default STT service is set to Google if available.
        if 'google' in self.stt_services:
            self.active_stt = self.stt_services['google']
            logger.info("Default STT set to Google.")

    # ----------------------- TTS Methods -----------------------

    async def text_to_speech(self, text: str, provider: str = None):
        """
        Converts text to speech using the specified provider.

        Args:
            text (str): The text to convert.
            provider (str, optional): The TTS provider key. If None, the default provider is used.
        """
        if not self.config_manager.get_tts_enabled():
            logger.info("TTS is disabled. Skipping TTS generation.")
            return

        provider = provider or self.get_default_tts_provider()
        tts = self.tts_services.get(provider)
        if not tts:
            logger.error(f"TTS provider '{provider}' not found.")
            return

        await tts.text_to_speech(text)

    def set_tts_voice(self, voice: dict, provider: str = None):
        """
        Sets the active voice for a given TTS provider.

        Args:
            voice (dict): Dictionary containing voice details.
            provider (str, optional): TTS provider key.
        """
        provider = provider or self.get_default_tts_provider()
        tts = self.tts_services.get(provider)
        if not tts:
            logger.error(f"TTS provider '{provider}' not found.")
            return
        tts.set_voice(voice)

    def get_tts_voices(self, provider: str = None) -> list:
        """
        Retrieves available voices from the specified TTS provider.

        Args:
            provider (str, optional): TTS provider key.

        Returns:
            list: List of available voices.
        """
        provider = provider or self.get_default_tts_provider()
        tts = self.tts_services.get(provider)
        if not tts:
            logger.error(f"TTS provider '{provider}' not found.")
            return []
        return tts.get_voices()

    def set_tts_status(self, value: bool, provider: str = None):
        """
        Enables or disables TTS for a specific provider or globally.

        Args:
            value (bool): True to enable TTS, False to disable.
            provider (str, optional): Specific TTS provider key. If None, applies globally.
        """
        if provider:
            tts = self.tts_services.get(provider)
            if not tts:
                logger.error(f"TTS provider '{provider}' not found.")
                return
            tts.set_tts(value)
            logger.info(f"TTS for provider '{provider}' set to {value}.")
        else:
            self._tts_enabled = value
            logger.info(f"Global TTS enabled set to {self._tts_enabled}.")

    def get_tts_status(self, provider: str = None) -> bool:
        """
        Gets the TTS enabled status for a specific provider or globally.

        Args:
            provider (str, optional): TTS provider key.

        Returns:
            bool: TTS enabled status.
        """
        if provider:
            tts = self.tts_services.get(provider)
            if not tts:
                logger.error(f"TTS provider '{provider}' not found.")
                return False
            return tts.get_tts()
        else:
            logger.info(f"Global TTS status: {self.config_manager.get_tts_enabled()}")
            return self.config_manager.get_tts_enabled()

    def add_tts_provider(self, name: str, tts_instance: Any):
        """
        Adds a new TTS provider.

        Args:
            name (str): Unique key for the provider.
            tts_instance (Any): Instance of the TTS provider.
        """
        if name in self.tts_services:
            logger.warning(f"TTS provider '{name}' already exists. Overwriting.")
        self.tts_services[name] = tts_instance
        logger.info(f"TTS provider '{name}' added.")

    def remove_tts_provider(self, name: str):
        """
        Removes a TTS provider.

        Args:
            name (str): Unique key for the provider.
        """
        if name in self.tts_services:
            del self.tts_services[name]
            logger.info(f"TTS provider '{name}' removed.")
        else:
            logger.warning(f"TTS provider '{name}' does not exist.")

    def get_default_tts_provider(self) -> str:
        """
        Retrieves the key for the default TTS provider.

        Returns:
            str: Default TTS provider key or None if not set.
        """
        if self.active_tts:
            for name, service in self.tts_services.items():
                if service == self.active_tts:
                    return name
        return None

    def set_default_tts_provider(self, provider: str):
        """
        Sets the default TTS provider.

        Args:
            provider (str): Unique key for the TTS provider.
        """
        tts = self.tts_services.get(provider)
        if not tts:
            logger.error(f"TTS provider '{provider}' not found.")
            return
        self.active_tts = tts
        logger.info(f"Default TTS provider set to '{provider}'.")

    # ----------------------- STT Methods -----------------------

    def listen(self, provider: str = None):
        """
        Starts speech recognition by invoking the active STT provider's listen method.

        Args:
            provider (str, optional): STT provider key.
        """
        provider = provider or self.get_default_stt_provider()
        stt = self.stt_services.get(provider)
        if not stt:
            logger.error(f"STT provider '{provider}' not found.")
            return
        stt.listen()

    def stop_listening(self, provider: str = None):
        """
        Stops speech recognition by invoking the active STT provider's stop_listening method.

        Args:
            provider (str, optional): STT provider key.
        """
        provider = provider or self.get_default_stt_provider()
        stt = self.stt_services.get(provider)
        if not stt:
            logger.error(f"STT provider '{provider}' not found.")
            return
        stt.stop_listening()

    def transcribe(self, audio_file: str, provider: str = None) -> str:
        """
        Transcribes the provided audio file using the active STT provider.

        Args:
            audio_file (str): The name or path of the audio file to transcribe.
            provider (str, optional): STT provider key.

        Returns:
            str: Transcribed text.
        """
        provider = provider or self.get_default_stt_provider()
        stt = self.stt_services.get(provider)
        if not stt:
            logger.error(f"STT provider '{provider}' not found.")
            return ""
        return stt.transcribe(audio_file)

    def add_stt_provider(self, name: str, stt_instance: Any):
        """
        Adds a new STT provider.

        Args:
            name (str): Unique key for the provider.
            stt_instance (Any): Instance of the STT provider.
        """
        if name in self.stt_services:
            logger.warning(f"STT provider '{name}' already exists. Overwriting.")
        self.stt_services[name] = stt_instance
        logger.info(f"STT provider '{name}' added.")

    def remove_stt_provider(self, name: str):
        """
        Removes an STT provider.

        Args:
            name (str): Unique key for the provider.
        """
        if name in self.stt_services:
            del self.stt_services[name]
            logger.info(f"STT provider '{name}' removed.")
        else:
            logger.warning(f"STT provider '{name}' does not exist.")

    def get_default_stt_provider(self) -> str:
        """
        Retrieves the key for the default STT provider.

        Returns:
            str: Default STT provider key or None if not set.
        """
        if self.active_stt:
            for name, service in self.stt_services.items():
                if service == self.active_stt:
                    return name
        return None

    def set_default_stt_provider(self, provider: str):
        """
        Sets the default STT provider.

        Args:
            provider (str): Unique key for the STT provider.
        """
        stt = self.stt_services.get(provider)
        if not stt:
            logger.error(f"STT provider '{provider}' not found.")
            return
        self.active_stt = stt
        logger.info(f"Default STT provider set to '{provider}'.")

    async def close(self):
        """
        Performs cleanup operations for all services that implement a close method.
        """
        # Close TTS services
        for name, tts in self.tts_services.items():
            if hasattr(tts, 'close') and callable(tts.close):
                await tts.close()
                logger.info(f"Closed TTS provider '{name}'.")

        # Close STT services
        for name, stt in self.stt_services.items():
            if hasattr(stt, 'close') and callable(stt.close):
                await stt.close()
                logger.info(f"Closed STT provider '{name}'.")


# GTKUI/Settings/Speech/speech_settings.py

"""
Module: speech_settings.py
Description:
    Enterprise production–ready Speech Settings window with a tabbed layout.
    The General tab now lets the user turn TTS and STT on or off independently and select
    the default providers for each.
    All Google settings (credentials used for both Google TTS and STT) are on a single Google tab.
    Separate tabs exist for Eleven Labs TTS and Whisper STT.
    
Author: Jeremy Shows - Digital Hallucinations
Date: 05-11-2025
"""

import gi
gi.require_version('Gtk', '4.0')
from gi.repository import Gtk, GLib
import os
import logging

from GTKUI.Utils.utils import apply_css

logger = logging.getLogger(__name__)

class SpeechSettings(Gtk.Window):
    def __init__(self, atlas):
        """
        Initializes the Speech Settings window with a tabbed interface.

        Args:
            atlas: The main ATLAS application instance.
        """
        super().__init__(title="Speech Settings")
        self.ATLAS = atlas

        # Use the same dark style classes as the rest of the UI
        self.get_style_context().add_class("chat-page")
        self.get_style_context().add_class("sidebar")
        
        # Apply global CSS (style.css)
        apply_css()

        self.set_default_size(500, 500)

        # Main container
        vbox = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
        vbox.set_margin_top(10)
        vbox.set_margin_bottom(10)
        vbox.set_margin_start(10)
        vbox.set_margin_end(10)
        self.set_child(vbox)

        # Create a Notebook for tabbed settings
        self.notebook = Gtk.Notebook()
        vbox.append(self.notebook)

        # Create each tab/page
        self.create_general_tab()
        self.create_eleven_labs_tts_tab()
        self.create_google_tab()
        self.create_whisper_stt_tab()

        # "Save Settings" button at the bottom of the window
        save_button = Gtk.Button(label="Save Settings")
        save_button.connect("clicked", self.on_save_clicked)
        vbox.append(save_button)

        self.present()

    # -------------------------------------------------------------------------
    #   TAB 1: GENERAL
    # -------------------------------------------------------------------------
    def create_general_tab(self):
        """
        Creates the "General" tab for overall speech-related settings.
        Contains separate switches to enable/disable TTS and STT,
        and selectors for the default TTS and STT providers.
        """
        general_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)
        general_box.set_margin_top(6)
        general_box.set_margin_bottom(6)
        general_box.set_margin_start(6)
        general_box.set_margin_end(6)

        # TTS Enable Switch
        tts_label = Gtk.Label(label="Enable TTS:")
        self.general_tts_switch = Gtk.Switch()
        current_tts_provider = self.ATLAS.speech_manager.get_default_tts_provider()
        self.general_tts_switch.set_active(self.ATLAS.speech_manager.get_tts_status(current_tts_provider))
        general_box.append(tts_label)
        general_box.append(self.general_tts_switch)

        # Default TTS Provider Selector
        tts_provider_label = Gtk.Label(label="Default TTS Provider:")
        self.default_tts_combo = Gtk.ComboBoxText()
        for key in self.ATLAS.speech_manager.tts_services.keys():
            self.default_tts_combo.append_text(key)
        # Set current active default provider if available.
        if current_tts_provider:
            index = list(self.ATLAS.speech_manager.tts_services.keys()).index(current_tts_provider)
            self.default_tts_combo.set_active(index)
        general_box.append(tts_provider_label)
        general_box.append(self.default_tts_combo)

        # STT Enable Switch
        stt_label = Gtk.Label(label="Enable STT:")
        self.general_stt_switch = Gtk.Switch()
        default_stt = self.ATLAS.speech_manager.get_default_stt_provider()
        stt_enabled = True if default_stt else False
        self.general_stt_switch.set_active(stt_enabled)
        general_box.append(stt_label)
        general_box.append(self.general_stt_switch)

        # Default STT Provider Selector
        stt_provider_label = Gtk.Label(label="Default STT Provider:")
        self.default_stt_combo = Gtk.ComboBoxText()
        for key in self.ATLAS.speech_manager.stt_services.keys():
            self.default_stt_combo.append_text(key)
        if default_stt:
            index = list(self.ATLAS.speech_manager.stt_services.keys()).index(default_stt)
            self.default_stt_combo.set_active(index)
        general_box.append(stt_provider_label)
        general_box.append(self.default_stt_combo)

        # Add the "General" page to the notebook
        self.notebook.append_page(general_box, Gtk.Label(label="General"))

    # -------------------------------------------------------------------------
    #   TAB 2: ELEVEN LABS TTS
    # -------------------------------------------------------------------------
    def create_eleven_labs_tts_tab(self):
        """
        Creates a tab specifically for Eleven Labs TTS settings:
        - Voice selection
        - Eleven Labs API key
        """
        eleven_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)
        eleven_box.set_margin_top(6)
        eleven_box.set_margin_bottom(6)
        eleven_box.set_margin_start(6)
        eleven_box.set_margin_end(6)

        # Voice selection combo box
        self.voice_combo = Gtk.ComboBoxText()
        current_tts_provider = self.ATLAS.speech_manager.get_default_tts_provider()
        voices = self.ATLAS.speech_manager.get_tts_voices(current_tts_provider)
        for voice in voices:
            voice_name = voice.get('name', 'Unknown')
            self.voice_combo.append_text(voice_name)
        if voices:
            self.voice_combo.set_active(0)
        eleven_box.append(Gtk.Label(label="Select TTS Voice:"))
        eleven_box.append(self.voice_combo)

        # Eleven Labs API key
        self.eleven_api_entry = Gtk.Entry()
        existing_xi_api = self.ATLAS.config_manager.get_config("XI_API_KEY") or ""
        self.eleven_api_entry.set_text(existing_xi_api)
        eleven_box.append(Gtk.Label(label="Eleven Labs API Key:"))
        eleven_box.append(self.eleven_api_entry)

        # Add the "Eleven Labs TTS" page to the notebook
        self.notebook.append_page(eleven_box, Gtk.Label(label="Eleven Labs TTS"))

    # -------------------------------------------------------------------------
    #   TAB 3: GOOGLE (TTS & STT)
    # -------------------------------------------------------------------------
    def create_google_tab(self):
        """
        Creates a tab for all Google settings used by both TTS and STT.
        Contains Google Cloud credentials.
        """
        google_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)
        google_box.set_margin_top(6)
        google_box.set_margin_bottom(6)
        google_box.set_margin_start(6)
        google_box.set_margin_end(6)

        # Google Cloud Credentials entry
        self.google_credentials_entry = Gtk.Entry()
        existing_google_creds = self.ATLAS.config_manager.get_config("GOOGLE_APPLICATION_CREDENTIALS") or ""
        self.google_credentials_entry.set_text(existing_google_creds)
        google_box.append(Gtk.Label(label="Google Cloud Credentials JSON Path:"))
        google_box.append(self.google_credentials_entry)

        google_box.append(Gtk.Label(label="These credentials are used for both Google TTS and STT."))

        self.notebook.append_page(google_box, Gtk.Label(label="Google"))

    # -------------------------------------------------------------------------
    #   TAB 4: WHISPER STT
    # -------------------------------------------------------------------------
    def create_whisper_stt_tab(self):
        """
        Creates a tab for Whisper STT settings:
        - Whisper mode (Local/Online)
        - OpenAI API key (for Whisper Online)
        """
        whisper_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)
        whisper_box.set_margin_top(6)
        whisper_box.set_margin_bottom(6)
        whisper_box.set_margin_start(6)
        whisper_box.set_margin_end(6)

        # Whisper mode selection combo box
        whisper_mode_label = Gtk.Label(label="Whisper Mode:")
        self.whisper_mode_combo = Gtk.ComboBoxText()
        self.whisper_mode_combo.append_text("Local")
        self.whisper_mode_combo.append_text("Online")
        self.whisper_mode_combo.set_active(0)
        whisper_box.append(whisper_mode_label)
        whisper_box.append(self.whisper_mode_combo)

        # OpenAI API key for Whisper Online
        self.openai_api_entry = Gtk.Entry()
        existing_openai_api = self.ATLAS.config_manager.get_config("OPENAI_API_KEY") or ""
        self.openai_api_entry.set_text(existing_openai_api)
        whisper_box.append(Gtk.Label(label="OpenAI API Key (for Whisper Online):"))
        whisper_box.append(self.openai_api_entry)

        self.notebook.append_page(whisper_box, Gtk.Label(label="Whisper STT"))

    # -------------------------------------------------------------------------
    #   SAVE SETTINGS
    # -------------------------------------------------------------------------
    def on_save_clicked(self, widget):
        """
        Handler for the "Save Settings" button.
        Gathers data from all tabs and updates the configuration manager and environment.
        Also updates the active TTS/STT providers in the Speech Manager.
        """
        # ---------------------------
        # General Tab: TTS and STT toggles & default provider selectors
        # ---------------------------
        tts_enabled = self.general_tts_switch.get_active()
        stt_enabled = self.general_stt_switch.get_active()
        current_tts_provider = self.ATLAS.speech_manager.get_default_tts_provider()
        self.ATLAS.speech_manager.set_tts_status(tts_enabled, current_tts_provider)
        logger.info(f"General settings - TTS enabled: {tts_enabled}, STT enabled: {stt_enabled}")

        # Update default providers based on selectors.
        selected_tts_provider = self.default_tts_combo.get_active_text()
        if selected_tts_provider:
            self.ATLAS.speech_manager.set_default_tts_provider(selected_tts_provider)
            logger.info(f"Default TTS provider set to: {selected_tts_provider}")

        if not stt_enabled:
            # Disable STT by setting active_stt to None.
            self.ATLAS.speech_manager.active_stt = None
            logger.info("STT has been disabled.")
        else:
            selected_stt_provider = self.default_stt_combo.get_active_text()
            if selected_stt_provider:
                self.ATLAS.speech_manager.set_default_stt_provider(selected_stt_provider)
                logger.info(f"Default STT provider set to: {selected_stt_provider}")
            else:
                logger.warning("STT enabled but no default provider was selected.")

        # ---------------------------
        # Google Tab: Update credentials
        # ---------------------------
        google_creds = self.google_credentials_entry.get_text().strip()
        self.ATLAS.config_manager.config["GOOGLE_APPLICATION_CREDENTIALS"] = google_creds
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = google_creds

        # ---------------------------
        # Eleven Labs TTS Tab: Update API key and voice
        # ---------------------------
        eleven_api_key = self.eleven_api_entry.get_text().strip()
        self.ATLAS.config_manager.config["XI_API_KEY"] = eleven_api_key
        os.environ["XI_API_KEY"] = eleven_api_key

        selected_voice_name = self.voice_combo.get_active_text()
        voices = self.ATLAS.speech_manager.get_tts_voices(self.ATLAS.speech_manager.get_default_tts_provider())
        selected_voice = next((v for v in voices if v.get('name') == selected_voice_name), None)
        if selected_voice:
            self.ATLAS.speech_manager.set_tts_voice(selected_voice, self.ATLAS.speech_manager.get_default_tts_provider())

                # ---------------------------
        # Whisper STT Tab: Update Whisper mode and OpenAI API key
        # ---------------------------
        openai_api_key = self.openai_api_entry.get_text().strip()
        self.ATLAS.config_manager.config["OPENAI_API_KEY"] = openai_api_key
        os.environ["OPENAI_API_KEY"] = openai_api_key
        whisper_mode = self.whisper_mode_combo.get_active_text().lower()  # Define whisper_mode here
        from modules.Speech_Services.whisper_stt import WhisperSTT
        try:
            whisper_stt = WhisperSTT(mode=whisper_mode)
            provider_key = f"whisper_{whisper_mode}"
            self.ATLAS.speech_manager.add_stt_provider(provider_key, whisper_stt)
            self.ATLAS.speech_manager.set_default_stt_provider(provider_key)
        except Exception as e:
            logger.error(f"Error setting Whisper mode: {e}")

        logger.info("Speech settings saved.")
        self.destroy()



# GTKUI/Utils/utils.py

"""
This module provides utility functions for the GTK application.
It includes methods to apply CSS styling from an external file and to create
Gtk.Box widgets with uniform margins and spacing.

Enterprise-level error handling and logging are implemented to ensure
robust operation in production environments.
"""

import os
import logging
import gi

# Require GTK version 4.0 for modern widget APIs
gi.require_version("Gtk", "4.0")
from gi.repository import Gtk, Gdk

# Set up a module-level logger for detailed debugging.
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)


def apply_css():
    """
    Applies CSS styling to the GTK application using an external CSS file.
    
    The CSS file is located relative to this module file for robust path resolution.
    The function uses a Gtk.CssProvider to load and apply the CSS to the default GDK display.
    
    Raises:
        FileNotFoundError: If the CSS file cannot be located.
        RuntimeError: If the default GDK display is unavailable.
    """
    css_provider = Gtk.CssProvider()
    # Compute the absolute path to the CSS file based on this file's directory.
    css_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "style.css")
    logger.debug(f"Attempting to load CSS from: {css_file_path}")

    try:
        # Ensure that the CSS file exists before attempting to load it.
        if not os.path.exists(css_file_path):
            raise FileNotFoundError(f"CSS file not found at {css_file_path}")

        # Load the CSS styling from the file.
        css_provider.load_from_path(css_file_path)
        logger.debug("CSS file loaded successfully.")

        # Retrieve the default GDK display.
        display = Gdk.Display.get_default()
        if display is None:
            raise RuntimeError("Unable to retrieve the default GDK display.")

        # Add the CSS provider to the display with high priority.
        Gtk.StyleContext.add_provider_for_display(
            display,
            css_provider,
            Gtk.STYLE_PROVIDER_PRIORITY_APPLICATION
        )
        logger.info(f"Successfully applied CSS from {css_file_path}")
    except Exception as e:
        logger.error(f"Failed to load external CSS file '{css_file_path}': {e}")


def create_box(orientation=Gtk.Orientation.VERTICAL, spacing=10, margin=10):
    """
    Creates a Gtk.Box widget with specified orientation, spacing, and uniform margins.
    
    This helper function centralizes box creation for consistent UI layout.
    
    Args:
        orientation (Gtk.Orientation): The orientation (VERTICAL or HORIZONTAL) for the box.
        spacing (int): Spacing (in pixels) between child widgets.
        margin (int): Uniform margin (in pixels) to apply on all sides.
    
    Returns:
        Gtk.Box: A configured Gtk.Box widget with the specified parameters.
    """
    box = Gtk.Box(orientation=orientation, spacing=spacing)
    box.set_margin_top(margin)
    box.set_margin_bottom(margin)
    box.set_margin_start(margin)
    box.set_margin_end(margin)
    return box

# GTKUI/Utils/style.css


/* Label Styling */
label {
    color: white;
    font-size: 14px;
}

/* Persona Label Styling */
#persona-label {
    font-size: 18px;
    font-weight: bold;
    text-transform: uppercase; /* Enhances prominence */
}

/* Message Bubble Styling */
.message-bubble { 
    border-radius: 18px; 
    padding: 8px 12px;
    margin: 4px 0;
    box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.3); /* Subtle shadow for depth */
}

/* User Message Styling */
.user-message { 
    background-color: #0084ff; 
    color: white;
    border-radius: 18px;
}

/* Assistant Message Styling */
.assistant-message { 
    background-color: #3c3c3c; 
    color: white;
    border-radius: 18px;
}

/* Entry (Input Field) Styling */
entry {
    background-color: #3c3c3c;
    color: white;
    border-radius: 20px;
    padding: 8px 12px;
    caret-color: white;
    border: 1px solid #555555; /* Subtle border for input field */
    font-size: 14px; /* Ensure readability */
    transition: background-color 0.3s, border-color 0.3s;
}

entry:focus {
    background-color: #444444;
    border-color: #888888; /* Highlighted border on focus */
}

/* Button Styling */
button {
    background-color: #555555;
    color: white;
    border-radius: 10px; /* Rounded buttons */
    border: 1px solid #777777;
    padding: 6px 12px;
    transition: background-color 0.3s, transform 0.2s;
    font-size: 14px;
}

/* Hover Effect for Buttons */
button:hover {
    background-color: #666666;
    transform: scale(1.05);
}

button:focus {
    border-color: #888888; /* Highlight border on focus */
}

/* Flat Button Styling */
button.flat {
    background-color: transparent;
    border: none;
    color: white;
    padding: 4px;
}

button.flat:hover {
    background-color: #444444;
    border-radius: 8px; /* Slight rounding on hover */
}

/* Status Bar Styling */
statusbar {
    background-color: #2b2b2b;
    color: white;
    padding: 4px 8px;
    font-size: 12px;
}

